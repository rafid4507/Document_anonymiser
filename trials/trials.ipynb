{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ff8698",
   "metadata": {},
   "source": [
    "jupitar notebook for doc anonymizer applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import os\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESSERACT_PATH = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update this path for your system\n",
    "pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH\n",
    "\n",
    "\n",
    "def get_llm_redaction_list(text_content):\n",
    "    \"\"\"\n",
    "    Step 3: Calls the Gemini API to identify PII in the text and request a structured JSON response.\n",
    "\n",
    "    In a real implementation, you would use a JSON Schema (responseSchema) \n",
    "    to force the model to return a structured list of the PII strings found.\n",
    "    \"\"\"\n",
    "    print(\"--- Sending text to LLM for PII analysis ---\")\n",
    "\n",
    "    # MOCK LLM RESPONSE FOR TESTING (In a real app, this would be a fetch/API call)\n",
    "    # The LLM identifies the specific text strings that are PII.\n",
    "    mock_llm_response_data = {\n",
    "        \"pii_items\": [\n",
    "            \"John Smith\", \n",
    "            \"555-123-4567\",\n",
    "            \"123 Fictional Ln\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # IMPORTANT: The LLM only sees the text. It must return the exact PII string.\n",
    "    # Your code will then match this string back to the OCR coordinates.\n",
    "    \n",
    "    return mock_llm_response_data['pii_items']\n",
    "\n",
    "\n",
    "def get_ocr_data(image_path):\n",
    "    \"\"\"\n",
    "    Step 2: Performs OCR and extracts word-level bounding box data.\n",
    "    \"\"\"\n",
    "    print(f\"--- Performing OCR on {image_path} ---\")\n",
    "    \n",
    "    # Use 'data' output which includes bounding box information\n",
    "    # Output format is typically: level, page_num, block_num, par_num, line_num, word_num, left, top, width, height, conf, text\n",
    "    data = pytesseract.image_to_data(Image.open(image_path), output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    # Structure the data to make it easier to search\n",
    "    ocr_words = []\n",
    "    for i in range(len(data['text'])):\n",
    "        text = data['text'][i].strip()\n",
    "        if text:\n",
    "            # We store the bounding box (x, y, w, h)\n",
    "            bbox = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "            ocr_words.append({'text': text, 'bbox': bbox})\n",
    "            \n",
    "    return ocr_words\n",
    "\n",
    "\n",
    "def redact_image(image_path, pii_list, ocr_words, output_dir=\"redacted_output\"):\n",
    "    \"\"\"\n",
    "    Step 4: Finds the coordinates for PII and redacts the image using OpenCV.\n",
    "    \"\"\"\n",
    "    print(f\"--- Redacting image: {image_path} ---\")\n",
    "    \n",
    "    # Load the image using OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Set the redaction color (black)\n",
    "    REDACTION_COLOR = (0, 0, 0) # BGR format\n",
    "    redaction_count = 0\n",
    "\n",
    "    # This is a simplification: finding exact PII phrases requires complex matching \n",
    "    # and aggregation of word bounding boxes.\n",
    "    for pii_text in pii_list:\n",
    "        pii_words = pii_text.split()\n",
    "        \n",
    "        # Simple lookup: Find the first word of the PII phrase\n",
    "        for word_data in ocr_words:\n",
    "            if word_data['text'] == pii_words[0]:\n",
    "                x, y, w, h = word_data['bbox']\n",
    "                \n",
    "                # Simple redaction just for the first word match. \n",
    "                # For full phrase matching (e.g., \"John Smith\"), you need to find\n",
    "                # the bounding boxes for all words in the phrase and combine them \n",
    "                # to create one large redaction box.\n",
    "                \n",
    "                # Draw a filled rectangle (the redaction box)\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), REDACTION_COLOR, -1)\n",
    "                redaction_count += 1\n",
    "\n",
    "    print(f\"Successfully redacted {redaction_count} potential words/segments.\")\n",
    "\n",
    "    # Save the redacted image\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_name = os.path.basename(image_path)\n",
    "    output_path = os.path.join(output_dir, f\"redacted_{base_name}\")\n",
    "    cv2.imwrite(output_path, img)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "def anonymize_document(file_path):\n",
    "    \"\"\"\n",
    "    Main function to handle PDF or Image input.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Anonymization for {file_path} ---\")\n",
    "    \n",
    "    temp_images = []\n",
    "    \n",
    "    # Step 1: Handle Input (Convert PDF to images if necessary)\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        # This requires Poppler\n",
    "        pages = convert_from_path(file_path)\n",
    "        for i, page in enumerate(pages):\n",
    "            img_path = f\"temp_page_{i}.png\"\n",
    "            page.save(img_path, 'PNG')\n",
    "            temp_images.append(img_path)\n",
    "    else:\n",
    "        temp_images.append(file_path)\n",
    "\n",
    "    redacted_images = []\n",
    "\n",
    "    for img_path in temp_images:\n",
    "        # Step 2: OCR Extraction\n",
    "        ocr_data = get_ocr_data(img_path)\n",
    "        \n",
    "        # Combine all extracted text into one string for the LLM\n",
    "        full_text = \" \".join([d['text'] for d in ocr_data])\n",
    "        \n",
    "        # Step 3: LLM Analysis (get list of PII strings)\n",
    "        pii_to_redact = get_llm_redaction_list(full_text)\n",
    "        \n",
    "        if pii_to_redact:\n",
    "            # Step 4: Redaction\n",
    "            redacted_path = redact_image(img_path, pii_to_redact, ocr_data)\n",
    "            if redacted_path:\n",
    "                redacted_images.append(redacted_path)\n",
    "\n",
    "        # Cleanup temporary files (only for PDF conversion)\n",
    "        if file_path.lower().endswith('.pdf'):\n",
    "            os.remove(img_path)\n",
    "            \n",
    "    # Step 5: Final Output\n",
    "    if file_path.lower().endswith('.pdf') and redacted_images:\n",
    "        # Convert redacted images back to a single PDF\n",
    "        output_pdf_path = os.path.join(\"redacted_output\", \"redacted_document.pdf\")\n",
    "        \n",
    "        # Requires PIL/Pillow\n",
    "        redacted_pages = [Image.open(img) for img in redacted_images]\n",
    "        if redacted_pages:\n",
    "            redacted_pages[0].save(\n",
    "                output_pdf_path, \n",
    "                \"PDF\", \n",
    "                resolution=100.0, \n",
    "                save_all=True, \n",
    "                append_images=redacted_pages[1:]\n",
    "            )\n",
    "            print(f\"\\n--- SUCCESS! Redacted PDF saved to: {output_pdf_path} ---\")\n",
    "\n",
    "    elif redacted_images:\n",
    "        print(f\"\\n--- SUCCESS! Redacted Image saved to: {redacted_images[0]} ---\")\n",
    "\n",
    "\n",
    "# --- Example Usage (Requires a file named 'sample.pdf' or 'sample.png' to be present) ---\n",
    "# if __name__ == '__main__':\n",
    "#     # NOTE: You must provide a real file path here for testing\n",
    "#     # anonymize_document('sample_document.pdf')\n",
    "#     pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc_anonymiser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
